seed: 0
debug: 0
# do_eval: 1
eval_mode: closed

proposer: 
  eval_mode: open
  prompt_key_1_differences: 0
  prompt_key_2_subactions: 0
  seed: 0
  n_retrieval_keys: 5
  model: Qwen
  filter_retrieval_keys: 5
  prompt_key_3_subaction_filtering: 0
  prompt_key_4_linking: 0
  do_eval: true
  # drop_unmatched_diffs: false
  
retriever:
  multiframe:
    nframes: 11
    frames_sep_seconds: 1 
  seed: 1
  eval_mode: open
  mode: 1
  log_imgs: false
  do_random_retrieval: false
  model_config: 
    model: "ViT-bigG-14"


frame_differencer:
  seed: 1
  system_prompt_key: 0
  prompt_key: 0
  prompt_key_multiframe: 0
  eval_mode: open
  model: "Qwen"
  log_imgs: false
  do_eval: true

fps_inference: 
  fitness: 4      # original fps is 8
  ballsports: 5   # original fps is 30
  diving: 6       # original fps is 12
  music: 1        # original fps is 30
  surgery: 1      # original fps is 30


logging: 
  name: gpt4o_easy
  results_dir: lmms/results/${logging.name}/seed_${seed}
  overwrite_ok: True # if False, then throws an error if the results_dir already exists
  verbose: 1 

data:
  split: easy
  debug: ${debug}
  eval_mode: ${eval_mode}  
  subset_mode: "0"


# lmm:
#   model: gpt-4o-2024-08-06
#   # downsample the fps to this value for inference ... we show the original fps as a comment. Applied in lmms.lmm_utils.make_prompt
#   fps_inference: 
#     fitness: 4      # original fps is 8
#     ballsports: 5   # original fps is 30
#     diving: 6       # original fps is 12
#     music: 1        # original fps is 30
#     surgery: 1      # original fps is 30
#   fps_warning: True  # gives warning if fps_inference is not divisible by the original fps in that dataset 
#   video_representation: frames
#   seed: ${seed}
#   max_imgs: 150
#   # for gemini models only, a video is encoded as mp4. This value is the set fps. Then, gemini api samples at 1fps. So if fps_gemini is 1, the model sees each frame.
#   fps_gemini: 1 
